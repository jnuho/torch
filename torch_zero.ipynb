{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tensors\n",
    "\n",
    "- Scalar\n",
    "- Vector\n",
    "- Matrix\n",
    "- Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape =  torch.Size([])\n",
      "ndim =  0\n",
      "scalar.item() =  7\n"
     ]
    }
   ],
   "source": [
    "# 1. scalar\n",
    "scalar = torch.tensor(7)\n",
    "print(\"shape = \", scalar.shape)\n",
    "print(\"ndim = \", scalar.ndim)\n",
    "print(\"scalar.item() = \", scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape =  torch.Size([3])\n",
      "ndim =  1\n"
     ]
    }
   ],
   "source": [
    "# 2. vector\n",
    "vector = torch.tensor([7, 7, 8])\n",
    "print(\"shape = \", vector.shape)\n",
    "print(\"ndim = \", vector.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 4, 5]])\n",
      "shape =  torch.Size([2, 3])\n",
      "ndim =  2\n"
     ]
    }
   ],
   "source": [
    "# 3. MATRIX\n",
    "MATRIX = torch.tensor([[1, 2, 3],\n",
    "                      [2, 4, 5]])\n",
    "print(MATRIX)\n",
    "print(\"shape = \", MATRIX.shape)\n",
    "print(\"ndim = \", MATRIX.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  1,   2,   3,   4],\n",
      "         [  3,   6,   9,  12],\n",
      "         [  2,   4,   5,   9]],\n",
      "\n",
      "        [[ 10,  20,  30,  40],\n",
      "         [ 30,  60,  90, 120],\n",
      "         [ 20,  40,  50,  90]]])\n",
      "torch.Size([2, 3, 4])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 4. TENSOR\n",
    "TENSOR = torch.tensor([[\n",
    "    [1, 2, 3, 4],\n",
    "    [3, 6, 9, 12],\n",
    "    [2, 4, 5, 9] ],\n",
    "    [[10, 20, 30, 40],\n",
    "    [30, 60, 90, 120],\n",
    "    [20, 40, 50, 90]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR.ndim) # == number of brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "3\n",
      "torch.Size([224, 224, 3])\n",
      "random_tensor =  tensor([[[0.9508, 0.9043, 0.0794],\n",
      "         [0.8317, 0.6823, 0.9257],\n",
      "         [0.6547, 0.2828, 0.7742],\n",
      "         ...,\n",
      "         [0.4926, 0.4197, 0.9968],\n",
      "         [0.8876, 0.2612, 0.5143],\n",
      "         [0.2128, 0.1540, 0.6192]],\n",
      "\n",
      "        [[0.0630, 0.3973, 0.8786],\n",
      "         [0.7388, 0.4045, 0.1463],\n",
      "         [0.5167, 0.5915, 0.4148],\n",
      "         ...,\n",
      "         [0.4314, 0.1129, 0.3522],\n",
      "         [0.2913, 0.5950, 0.4366],\n",
      "         [0.4573, 0.8633, 0.5080]],\n",
      "\n",
      "        [[0.7661, 0.3839, 0.2150],\n",
      "         [0.6799, 0.3416, 0.6575],\n",
      "         [0.5892, 0.3318, 0.8665],\n",
      "         ...,\n",
      "         [0.6566, 0.4546, 0.9109],\n",
      "         [0.6139, 0.2293, 0.8545],\n",
      "         [0.9227, 0.4840, 0.5465]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.2390, 0.1148, 0.6618],\n",
      "         [0.9858, 0.7771, 0.8654],\n",
      "         [0.9198, 0.1795, 0.1070],\n",
      "         ...,\n",
      "         [0.0662, 0.0331, 0.4291],\n",
      "         [0.8423, 0.2375, 0.9065],\n",
      "         [0.0047, 0.8765, 0.1155]],\n",
      "\n",
      "        [[0.1851, 0.4005, 0.5771],\n",
      "         [0.9765, 0.8225, 0.3089],\n",
      "         [0.7359, 0.0489, 0.7054],\n",
      "         ...,\n",
      "         [0.6110, 0.4005, 0.0899],\n",
      "         [0.8321, 0.4273, 0.4576],\n",
      "         [0.7443, 0.7908, 0.2066]],\n",
      "\n",
      "        [[0.7390, 0.8248, 0.4924],\n",
      "         [0.0821, 0.6278, 0.6712],\n",
      "         [0.8226, 0.2537, 0.0460],\n",
      "         ...,\n",
      "         [0.1889, 0.1826, 0.1047],\n",
      "         [0.8473, 0.9635, 0.7094],\n",
      "         [0.2904, 0.6585, 0.5623]]])\n"
     ]
    }
   ],
   "source": [
    "# random_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_tensor = torch.rand(224, 224, 3)\n",
    "print(random_tensor.dtype)\n",
    "print(random_tensor.ndim)\n",
    "print(random_tensor.shape)\n",
    "print(\"random_tensor = \", random_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3, 4))\n",
    "print(zeros)\n",
    "\n",
    "ones = torch.ones(3,4)\n",
    "print(ones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a range and tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# zero_to_ten_deprecated = torch.range(0, 10)\n",
    "# print(zero_to_ten_deprecated)\n",
    "\n",
    "zeros_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "print(zeros_to_ten)\n",
    "\n",
    "ten_zeros = torch.zeros_like(input=zeros_to_ten)\n",
    "print(ten_zeros)\n",
    "ten_ones = torch.ones_like(input=zeros_to_ten)\n",
    "print(ten_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor datatypes\n",
    "\n",
    "- For precision in computing!\n",
    "- The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "- Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
    "- The most common type (and generally the default) is `torch.float32` or `torch.float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For precision in computing!\n",
    "# The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "# `torch.float32` or `torch.float`\n",
    "\n",
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tensor operations\n",
    "\n",
    "## Addition\n",
    "## Substraction\n",
    "## Multiplication (element-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n",
      "tensor([1, 4, 9])\n",
      "tensor([1, 4, 9])\n",
      "----Matrix multiplication----\n",
      "tensor(14)\n",
      "tensor(14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor * tensor)\n",
    "print(torch.mul(tensor, tensor))\n",
    "print(torch.mul(tensor, tensor))\n",
    "# Division\n",
    "print(\"----Matrix multiplication----\")\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(torch.matmul(tensor, tensor))\n",
    "print(tensor @ tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "CPU times: total: 6.84 s\n",
      "Wall time: 7.15 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(333332833333500000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# tensor = torch.tensor([1, 2, 3])\n",
    "tensor = torch.arange(start=0, end=1000000, step=1)\n",
    "\n",
    "# Matrix multiplication by hand \n",
    "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
    "value = 0\n",
    "print(len(tensor))\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(333332833333500000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMON ERRORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common issues: mismatch in tensor `shape`, `datatype` and `device`\n",
    "\n",
    "For example, one of tensors is torch.float32 and the other is torch.float16 (PyTorch often likes tensors to be the same format).\n",
    "\n",
    "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape - what shape is the tensor? (some operations require specific shape rules)\n",
      "dtype - what datatype are the elements within the tensor stored in?\n",
      "device - what device is the tensor stored on? (usually GPU or CPU)\n",
      "\n",
      "tensor([[0.5328, 0.4264, 0.4994, 0.4024],\n",
      "        [0.3332, 0.8220, 0.1778, 0.1137],\n",
      "        [0.4973, 0.1220, 0.7285, 0.7457]])\n",
      "Dimension (ndim) of tensor: 2\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Getting information from tensors\n",
    "print(\"shape - what shape is the tensor? (some operations require specific shape rules)\")\n",
    "print(\"dtype - what datatype are the elements within the tensor stored in?\")\n",
    "print(\"device - what device is the tensor stored on? (usually GPU or CPU)\\n\")\n",
    "\n",
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Dimension (ndim) of tensor: {some_tensor.ndim}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m],\n\u001b[0;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m],\n\u001b[0;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m6\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[0;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m], \n\u001b[0;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(tensor_A, tensor_B.T))\n",
    "print(torch.mm(tensor_A, tensor_B.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neural networks are full of matrix multiplications and dot products.\n",
    "\n",
    "The `torch.nn.Linear()` module (we'll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input x and a weights matrix A.\n",
    "\n",
    "\n",
    "$y = x \\cdot A^T + b$\n",
    "\n",
    "Try changing the values of in_features and out_features below and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# This uses matrix multiplication\u001b[39;00m\n\u001b[0;32m      4\u001b[0m linear \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;66;03m# in_features = matches inner dimension of input \u001b[39;00m\n\u001b[0;32m      5\u001b[0m                          out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m) \u001b[38;5;66;03m# out_features = describes outer value \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "\n",
    "x = torch.tensor([[1, 2],\n",
    "                [3, 4],\n",
    "                [5, 6]], dtype=torch.float32)\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Finding the min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(90), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "\n",
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # this will error\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")\n",
    "\n",
    "\n",
    "torch.min(x), torch.max(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change tensor datatype\n",
      "torch.float32\n",
      "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.])\n",
      "torch.float16\n",
      "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)\n",
      "torch.int8\n",
      "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(\"Change tensor datatype\")\n",
    "# Create a tensor and check its datatype\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "print(tensor.dtype)\n",
    "print(tensor)\n",
    "\n",
    "# Create a float16 tensor\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "print(tensor_float16.dtype)\n",
    "print(tensor_float16)\n",
    "\n",
    "# Create a int8 tensor\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "print(tensor_int8.dtype)\n",
    "print(tensor_int8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing\n",
    "\n",
    "Method\t| One-line description\n",
    "---|---\n",
    "`torch.reshape(input, shape)`\t| Reshapes input to shape (if compatible), can also use torch.Tensor.reshape().\n",
    "`Tensor.view(shape)`\t|Returns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
    "`torch.stack(tensors, dim=0)`\t|Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
    "`torch.squeeze(input)`\t|Squeezes input to remove all the dimenions with value 1.\n",
    "`torch.unsqueeze(input, dim)`\t|Returns input with a dimension value of 1 added at dim.\n",
    "`torch.permute(input, dims)`\t|Returns a view of the original input with its dimensions permuted (rearranged) to dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "torch.Size([10])\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(0., 10.)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "x_reshaped = x.reshape(10)\n",
    "print(x_reshaped)\n",
    "x_reshaped = x.reshape(1, 10)\n",
    "print(x_reshaped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view\n",
    "A tensor view in PyTorch is a way to create a new tensor that shares the same data as the original tensor but has a different shape or strides.\n",
    "\n",
    "Views are used to reshape, transpose, or otherwise change the view of the data without copying the underlying data.\n",
    "This makes operations more memory-efficient and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 1., 2., 3., 4.],\n",
       "         [5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(x)\n",
    "z = x.view(2, 5)\n",
    "print(z)\n",
    "\n",
    "# Changing view (z) changes x\n",
    "z[:, 0] = 5\n",
    "z, x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "tensor([[5., 5., 5., 5.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [8., 8., 8., 8.],\n",
      "        [9., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "print(x_stacked)\n",
    "\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "\n",
    "print(x_stacked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Squeeze---\n",
      "Previous tensor: tensor([[5., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 10])\n",
      "\n",
      "New tensor: tensor([5., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([10])\n",
      "---Unsqueeze---\n",
      "Previous tensor: tensor([5., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([10])\n",
      "\n",
      "New tensor: tensor([[5., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Stack tensors on top of each other\n",
    "print(\"---Squeeze---\")\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")\n",
    "\n",
    "print(\"---Unsqueeze---\")\n",
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# And to do the reverse of torch.squeeze() you can use torch.unsqueeze() to add a dimension value of 1 at a specific index.\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Permute-----\n",
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"-----Permute-----\")\n",
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Sometimes you'll want to select specific data from tensors (for example, only the first column or second row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "x.shape =  torch.Size([1, 3, 3])\n",
      "--------\n",
      "x[0] = First square bracket = tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "x[0][0] = Second square bracket = tensor([1, 2, 3])\n",
      "x[0][0][0] = Third square bracket = 1\n",
      "tensor([[1, 4, 7]])\n",
      "tensor([[1, 2, 3]])\n",
      "tensor([[2, 5, 8]])\n",
      "tensor([5])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor \n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "print(\"x = \", x)\n",
    "print(\"x.shape = \", x.shape)\n",
    "print(\"--------\")\n",
    "\n",
    "# Let's index bracket by bracket\n",
    "print(f\"x[0] = First square bracket = {x[0]}\") \n",
    "print(f\"x[0][0] = Second square bracket = {x[0][0]}\") \n",
    "print(f\"x[0][0][0] = Third square bracket = {x[0][0][0]}\")\n",
    "\n",
    "print(x[:, :, 0])\n",
    "\n",
    "# You can also use : to specify \"all values in this dimension\" and then use a comma (,) to add another dimension.\n",
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "print(x[:, 0])\n",
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "print(x[:, :, 1])\n",
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "print(x[:, 1, 1])\n",
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
    "print(x[0, 0, :]) # same as x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
