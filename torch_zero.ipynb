{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tensors\n",
    "\n",
    "- Scalar\n",
    "- Vector\n",
    "- Matrix\n",
    "- Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape =  torch.Size([])\n",
      "ndim =  0\n",
      "scalar.item() =  7\n"
     ]
    }
   ],
   "source": [
    "# 1. scalar\n",
    "scalar = torch.tensor(7)\n",
    "print(\"shape = \", scalar.shape)\n",
    "print(\"ndim = \", scalar.ndim)\n",
    "print(\"scalar.item() = \", scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape =  torch.Size([3])\n",
      "ndim =  1\n"
     ]
    }
   ],
   "source": [
    "# 2. vector\n",
    "vector = torch.tensor([7, 7, 8])\n",
    "print(\"shape = \", vector.shape)\n",
    "print(\"ndim = \", vector.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 4, 5]])\n",
      "shape =  torch.Size([2, 3])\n",
      "ndim =  2\n"
     ]
    }
   ],
   "source": [
    "# 3. MATRIX\n",
    "MATRIX = torch.tensor([[1, 2, 3],\n",
    "                      [2, 4, 5]])\n",
    "print(MATRIX)\n",
    "print(\"shape = \", MATRIX.shape)\n",
    "print(\"ndim = \", MATRIX.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  1,   2,   3,   4],\n",
      "         [  3,   6,   9,  12],\n",
      "         [  2,   4,   5,   9]],\n",
      "\n",
      "        [[ 10,  20,  30,  40],\n",
      "         [ 30,  60,  90, 120],\n",
      "         [ 20,  40,  50,  90]]])\n",
      "torch.Size([2, 3, 4])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# 4. TENSOR\n",
    "TENSOR = torch.tensor([[\n",
    "    [1, 2, 3, 4],\n",
    "    [3, 6, 9, 12],\n",
    "    [2, 4, 5, 9] ],\n",
    "    [[10, 20, 30, 40],\n",
    "    [30, 60, 90, 120],\n",
    "    [20, 40, 50, 90]]])\n",
    "print(TENSOR)\n",
    "print(TENSOR.shape)\n",
    "print(TENSOR.ndim) # == number of brackets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "3\n",
      "torch.Size([224, 224, 3])\n",
      "random_tensor =  tensor([[[8.3810e-01, 3.5759e-01, 2.4085e-01],\n",
      "         [2.3288e-01, 8.8651e-01, 9.6280e-01],\n",
      "         [2.0873e-01, 1.3244e-01, 5.6792e-01],\n",
      "         ...,\n",
      "         [6.6686e-01, 9.8580e-01, 7.3381e-01],\n",
      "         [3.4252e-01, 6.2527e-02, 1.9630e-01],\n",
      "         [1.1508e-01, 4.2583e-01, 2.4190e-01]],\n",
      "\n",
      "        [[9.3329e-01, 9.1714e-01, 9.5501e-01],\n",
      "         [9.8000e-01, 7.6415e-01, 7.0096e-01],\n",
      "         [7.3076e-01, 4.8098e-01, 9.6802e-01],\n",
      "         ...,\n",
      "         [4.2055e-01, 9.3231e-01, 4.7745e-01],\n",
      "         [5.4122e-01, 8.9984e-01, 6.8282e-01],\n",
      "         [1.2178e-03, 8.8838e-01, 9.9388e-01]],\n",
      "\n",
      "        [[9.2399e-01, 5.2803e-01, 2.6855e-01],\n",
      "         [9.3570e-01, 2.0317e-01, 2.5086e-01],\n",
      "         [8.5419e-01, 5.2427e-01, 7.4775e-02],\n",
      "         ...,\n",
      "         [5.7344e-01, 4.5856e-01, 5.8683e-01],\n",
      "         [8.5996e-01, 1.6108e-01, 4.7880e-01],\n",
      "         [7.1471e-01, 7.7475e-01, 3.9974e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.0168e-01, 6.6538e-01, 8.6956e-01],\n",
      "         [3.4977e-01, 9.0298e-01, 5.7605e-01],\n",
      "         [5.4659e-01, 3.2117e-01, 1.0442e-01],\n",
      "         ...,\n",
      "         [9.6197e-01, 9.8443e-01, 1.0680e-02],\n",
      "         [4.0926e-01, 4.3505e-01, 2.2680e-01],\n",
      "         [9.4140e-01, 6.8661e-01, 8.7119e-01]],\n",
      "\n",
      "        [[5.8189e-01, 1.7413e-01, 4.3269e-01],\n",
      "         [5.6765e-01, 1.1389e-01, 4.4532e-01],\n",
      "         [4.8832e-01, 9.4820e-01, 8.5291e-01],\n",
      "         ...,\n",
      "         [1.3706e-01, 6.3163e-02, 2.8278e-01],\n",
      "         [5.9017e-01, 2.0306e-01, 5.7940e-01],\n",
      "         [7.8201e-01, 6.5775e-01, 7.1055e-02]],\n",
      "\n",
      "        [[9.7868e-01, 7.0627e-01, 8.7859e-01],\n",
      "         [2.4082e-02, 7.1660e-01, 6.3497e-01],\n",
      "         [2.1273e-04, 5.3152e-01, 3.9062e-01],\n",
      "         ...,\n",
      "         [1.6720e-03, 4.4750e-01, 5.5632e-02],\n",
      "         [6.6058e-01, 6.6913e-01, 7.1739e-01],\n",
      "         [5.4708e-01, 7.5095e-01, 8.3273e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# random_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_tensor = torch.rand(224, 224, 3)\n",
    "print(random_tensor.dtype)\n",
    "print(random_tensor.ndim)\n",
    "print(random_tensor.shape)\n",
    "print(\"random_tensor = \", random_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3, 4))\n",
    "print(zeros)\n",
    "\n",
    "ones = torch.ones(3,4)\n",
    "print(ones)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a range and tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# zero_to_ten_deprecated = torch.range(0, 10)\n",
    "# print(zero_to_ten_deprecated)\n",
    "\n",
    "zeros_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "print(zeros_to_ten)\n",
    "\n",
    "ten_zeros = torch.zeros_like(input=zeros_to_ten)\n",
    "print(ten_zeros)\n",
    "ten_ones = torch.ones_like(input=zeros_to_ten)\n",
    "print(ten_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor datatypes\n",
    "\n",
    "- For precision in computing!\n",
    "- The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "- Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
    "- The most common type (and generally the default) is `torch.float32` or `torch.float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For precision in computing!\n",
    "# The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "# `torch.float32` or `torch.float`\n",
    "\n",
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                               device=None, # defaults to None, which uses the default tensor type. 'cpu', 'cuda', 'cuda:0'\n",
    "                               requires_grad=False) # if True, operations performed on the tensor are recorded \n",
    "\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 1. CPU\n",
    "cpu_tensor = torch.tensor([1, 2, 3], device='cpu')\n",
    "# or simply\n",
    "cpu_tensor = torch.tensor([1, 2, 3])  # defaults to CPU\n",
    "print(cpu_tensor.device)  # Output: device(type='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. GPU (if available)\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = torch.tensor([1, 2, 3], device='cuda')\n",
    "    # or\n",
    "    gpu_tensor = torch.tensor([1, 2, 3], device='cuda:0')  # first GPU\n",
    "    print(gpu_tensor.device)  # Output: device(type='cuda', index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Moving tensors between devices:\n",
    "\n",
    "cpu_tensor = torch.tensor([1, 2, 3])\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = cpu_tensor.to('cuda')\n",
    "    print(gpu_tensor.device)  # Output: device(type='cuda', index=0)\n",
    "    \n",
    "    # Move back to CPU\n",
    "    new_cpu_tensor = gpu_tensor.to('cpu')\n",
    "    print(new_cpu_tensor.device)  # Output: device(type='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Multiple GPUs:\n",
    "if torch.cuda.device_count() > 1:\n",
    "    gpu_1_tensor = torch.tensor([1, 2, 3], device='cuda:1')  # second GPU\n",
    "    print(gpu_1_tensor.device)  # Output: device(type='cuda', index=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Tensor operations\n",
    "\n",
    "## Basic operation\n",
    "\n",
    "- Addition, Substraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-90, -80, -70])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "tensor + 10\n",
    "\n",
    "# Subtract and reassign\n",
    "tensor = tensor - 10\n",
    "tensor\n",
    "\n",
    "# Multiply it by 10\n",
    "tensor * 10\n",
    "# Can also use torch functions\n",
    "torch.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiplication\n",
    "\n",
    "### `torch.mul` vs. `torch.matmul` (or @)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 4, 9])\n",
      "tensor([1, 4, 9])\n",
      "tensor([1, 4, 9])\n",
      "----Matrix multiplication----\n",
      "tensor(14)\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"----1. Matrix element-wise multiplication----\")\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor * tensor)\n",
    "print(torch.mul(tensor, tensor))\n",
    "print(torch.mul(tensor, tensor))\n",
    "\n",
    "print(\"----2. Matrix multiplication (or @) ----\")\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(torch.matmul(tensor, tensor))\n",
    "print(tensor @ tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `matmul()` time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "CPU times: user 3.81 s, sys: 1.55 ms, total: 3.81 s\n",
      "Wall time: 3.76 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(333332833333500000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# tensor = torch.tensor([1, 2, 3])\n",
    "tensor = torch.arange(start=0, end=1000000, step=1)\n",
    "\n",
    "# 1. COMPUTE manually compute sum of Element-wise multiplication\n",
    "# Matrix multiplication by hand \n",
    "# (avoid doing operations with for loops at all cost, they are computationally expensive)\n",
    "value = 0\n",
    "print(len(tensor))\n",
    "for i in range(len(tensor)):\n",
    "  value += tensor[i] * tensor[i]\n",
    "value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.2 ms, sys: 254 μs, total: 1.45 ms\n",
      "Wall time: 720 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(333332833333500000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 2. COMPUTE with Matric Multiplication: Faster\n",
    "torch.matmul(tensor, tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMMON ERRORS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common issues: mismatch in tensor `shape`, `datatype` and `device`\n",
    "\n",
    "For example, one of tensors is torch.float32 and the other is torch.float16 (PyTorch often likes tensors to be the same format).\n",
    "\n",
    "Or one of your tensors is on the CPU and the other is on the GPU (PyTorch likes calculations between tensors to be on the same device).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape - what shape is the tensor? (some operations require specific shape rules)\n",
      "dtype - what datatype are the elements within the tensor stored in?\n",
      "device - what device is the tensor stored on? (usually GPU or CPU)\n",
      "\n",
      "tensor([[0.4421, 0.9540, 0.1632, 0.5064],\n",
      "        [0.3561, 0.1311, 0.2433, 0.4058],\n",
      "        [0.4824, 0.8748, 0.1188, 0.6754]])\n",
      "Dimension (ndim) of tensor: 2\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Getting information from tensors\n",
    "print(\"shape - what shape is the tensor? (some operations require specific shape rules)\")\n",
    "print(\"dtype - what datatype are the elements within the tensor stored in?\")\n",
    "print(\"device - what device is the tensor stored on? (usually GPU or CPU)\\n\")\n",
    "\n",
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Dimension (ndim) of tensor: {some_tensor.ndim}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") # will default to CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m\n\u001b[1;32m      6\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m11\u001b[39m], \n\u001b[1;32m      8\u001b[0m                          [\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m12\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# ERROR: 3x2 * 3x2\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (this will error)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way  \n",
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "# ERROR: 3x2 * 3x2\n",
    "torch.matmul(tensor_A, tensor_B) # (this will error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n",
      "tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.matmul(tensor_A, tensor_B.T))\n",
    "print(torch.mm(tensor_A, tensor_B.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Multiplication visual\n",
    "\n",
    "- http://matrixmultiplication.xyz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Neural networks are full of matrix multiplications and dot products.\n",
    "\n",
    "The `torch.nn.Linear()` module (we'll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input x and a weights matrix A.\n",
    "\n",
    "\n",
    "$y = x \\cdot A^T + b$\n",
    "\n",
    "Try changing the values of in_features and out_features below and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5406,  0.5869],\n",
      "        [-0.1657,  0.6496],\n",
      "        [-0.1549,  0.1427],\n",
      "        [-0.3443,  0.4153],\n",
      "        [ 0.6233, -0.5188],\n",
      "        [ 0.6146,  0.1323]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.5224,  0.0958,  0.3410, -0.0998,  0.5451,  0.1045],\n",
      "       requires_grad=True)\n",
      "Input shape: torch.Size([3, 2])\n",
      "\n",
      "Output:\n",
      "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
      "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
      "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Output shape: torch.Size([3, 6])\n"
     ]
    }
   ],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "# This uses matrix multiplication\n",
    "# creates a linear layer, which is indeed a linear function with weights and bias.\n",
    "linear = torch.nn.Linear(in_features=2, # in_features = matches inner dimension of input \n",
    "                         out_features=6) # out_features = describes outer value \n",
    "print(linear.weight)\n",
    "print(linear.bias)\n",
    "\n",
    "x = torch.tensor([[1, 2],\n",
    "                [3, 4],\n",
    "                [5, 6]], dtype=torch.float32)\n",
    "# output = x cdot A^T + b\n",
    "output = linear(x)\n",
    "print(f\"Input shape: {x.shape}\\n\")\n",
    "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.5406,  0.5869],\n",
      "        [-0.1657,  0.6496],\n",
      "        [-0.1549,  0.1427],\n",
      "        [-0.3443,  0.4153],\n",
      "        [ 0.6233, -0.5188],\n",
      "        [ 0.6146,  0.1323]], requires_grad=True)\n",
      "\n",
      "Initial bias:\n",
      "Parameter containing:\n",
      "tensor([ 0.5224,  0.0958,  0.3410, -0.0998,  0.5451,  0.1045],\n",
      "       requires_grad=True)\n",
      "\n",
      "Epoch [250/1000], Loss: 132.7760\n",
      "Current weights:\n",
      "Parameter containing:\n",
      "tensor([[ 1.2352,  2.2655],\n",
      "        [ 0.9755,  4.3447],\n",
      "        [ 1.3678,  5.7714],\n",
      "        [ 1.3095,  7.7035],\n",
      "        [ 2.4315,  8.4713],\n",
      "        [ 2.3073, 10.4693]], requires_grad=True)\n",
      "Current bias:\n",
      "Parameter containing:\n",
      "tensor([1.5064, 2.6497, 4.4469, 5.5346, 7.7271, 8.7488], requires_grad=True)\n",
      "\n",
      "Epoch [500/1000], Loss: 86.4376\n",
      "Current weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.8663,  2.4411],\n",
      "        [-0.0640,  4.8395],\n",
      "        [-0.3422,  6.5854],\n",
      "        [-1.0912,  8.8463],\n",
      "        [-0.6659,  9.9457],\n",
      "        [-1.4808, 12.2724]], requires_grad=True)\n",
      "Current bias:\n",
      "Parameter containing:\n",
      "tensor([ 2.0509,  4.1840,  6.9710,  9.0781, 12.2987, 14.3400],\n",
      "       requires_grad=True)\n",
      "\n",
      "Epoch [750/1000], Loss: 56.2711\n",
      "Current weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.5687,  2.5828],\n",
      "        [-0.9028,  5.2387],\n",
      "        [-1.7220,  7.2421],\n",
      "        [-3.0283,  9.7683],\n",
      "        [-3.1650, 11.1352],\n",
      "        [-4.5371, 13.7273]], requires_grad=True)\n",
      "Current bias:\n",
      "Parameter containing:\n",
      "tensor([ 2.4902,  5.4221,  9.0075, 11.9372, 15.9874, 18.8512],\n",
      "       requires_grad=True)\n",
      "\n",
      "Epoch [1000/1000], Loss: 36.6327\n",
      "Current weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.3285,  2.6971],\n",
      "        [-1.5795,  5.5609],\n",
      "        [-2.8352,  7.7720],\n",
      "        [-4.5912, 10.5122],\n",
      "        [-5.1813, 12.0950],\n",
      "        [-7.0032, 14.9011]], requires_grad=True)\n",
      "Current bias:\n",
      "Parameter containing:\n",
      "tensor([ 2.8447,  6.4209, 10.6506, 14.2440, 18.9635, 22.4910],\n",
      "       requires_grad=True)\n",
      "\n",
      "Final weights:\n",
      "Parameter containing:\n",
      "tensor([[ 0.3285,  2.6971],\n",
      "        [-1.5795,  5.5609],\n",
      "        [-2.8352,  7.7720],\n",
      "        [-4.5912, 10.5122],\n",
      "        [-5.1813, 12.0950],\n",
      "        [-7.0032, 14.9011]], requires_grad=True)\n",
      "\n",
      "Final bias:\n",
      "Parameter containing:\n",
      "tensor([ 2.8447,  6.4209, 10.6506, 14.2440, 18.9635, 22.4910],\n",
      "       requires_grad=True)\n",
      "\n",
      "Prediction for input [7, 8]:\n",
      "tensor([[26.7215, 39.8512, 52.9802, 66.2034, 79.4542, 92.6775]])\n",
      "\n",
      "Initial output:\n",
      "tensor([[ 8.5675, 15.9631, 23.3594, 30.6772, 37.9722, 45.2900],\n",
      "        [14.6188, 23.9258, 33.2330, 42.5193, 51.7995, 61.0858],\n",
      "        [20.6702, 31.8885, 43.1066, 54.3614, 65.6269, 76.8816]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Final output:\n",
      "tensor([[ 8.5663, 15.9597, 23.3537, 30.6692, 37.9619, 45.2774],\n",
      "        [14.6185, 23.9249, 33.2315, 42.5172, 51.7968, 61.0825],\n",
      "        [20.6707, 31.8901, 43.1093, 54.3651, 65.6317, 76.8876]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "\n",
      "Target output:\n",
      "tensor([[10., 20., 30., 40., 50., 60.],\n",
      "        [15., 25., 35., 45., 55., 65.],\n",
      "        [20., 30., 40., 50., 60., 70.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define the linear model\n",
    "linear = nn.Linear(in_features=2, out_features=6)\n",
    "\n",
    "# Print initial parameters\n",
    "print(\"Initial weights:\")\n",
    "print(linear.weight)\n",
    "print(\"\\nInitial bias:\")\n",
    "print(linear.bias)\n",
    "\n",
    "# Create some dummy data\n",
    "x = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)\n",
    "y = torch.tensor([[10, 20, 30, 40, 50, 60],\n",
    "                  [15, 25, 35, 45, 55, 65],\n",
    "                  [20, 30, 40, 50, 60, 70]], dtype=torch.float32)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(linear.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = linear(x)\n",
    "    loss = criterion(outputs, y)\n",
    "    \n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print progress and parameters at certain intervals\n",
    "    if (epoch + 1) % 250 == 0:\n",
    "        print(f'\\nEpoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        print(\"Current weights:\")\n",
    "        print(linear.weight)\n",
    "        print(\"Current bias:\")\n",
    "        print(linear.bias)\n",
    "\n",
    "# Print final parameters\n",
    "print(\"\\nFinal weights:\")\n",
    "print(linear.weight)\n",
    "print(\"\\nFinal bias:\")\n",
    "print(linear.bias)\n",
    "\n",
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    test_input = torch.tensor([[7, 8]], dtype=torch.float32)\n",
    "    initial_prediction = linear(test_input)\n",
    "    print(\"\\nPrediction for input [7, 8]:\")\n",
    "    print(initial_prediction)\n",
    "\n",
    "# Compare initial and final outputs\n",
    "initial_output = linear(x)\n",
    "print(\"\\nInitial output:\")\n",
    "print(initial_output)\n",
    "print(\"\\nFinal output:\")\n",
    "print(outputs)\n",
    "print(\"\\nTarget output:\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Finding the min, max, mean, sum, etc (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(90), tensor(45.), tensor(450))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "\n",
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # this will error\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\") # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")\n",
    "\n",
    "\n",
    "torch.min(x), torch.max(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change tensor datatype\n",
      "torch.float32\n",
      "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.])\n",
      "torch.float16\n",
      "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)\n",
      "torch.int8\n",
      "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(\"Change tensor datatype\")\n",
    "# Create a tensor and check its datatype\n",
    "tensor = torch.arange(10., 100., 10.)\n",
    "print(tensor.dtype)\n",
    "print(tensor)\n",
    "\n",
    "# Create a float16 tensor\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "print(tensor_float16.dtype)\n",
    "print(tensor_float16)\n",
    "\n",
    "# Create a int8 tensor\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "print(tensor_int8.dtype)\n",
    "print(tensor_int8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing\n",
    "\n",
    "Method\t| One-line description\n",
    "---|---\n",
    "`torch.reshape(input, shape)`\t| Reshapes input to shape (if compatible), can also use torch.Tensor.reshape().\n",
    "`Tensor.view(shape)`\t|Returns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
    "`torch.stack(tensors, dim=0)`\t|Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
    "`torch.squeeze(input)`\t|Squeezes input to remove all the dimenions with value 1.\n",
    "`torch.unsqueeze(input, dim)`\t|Returns input with a dimension value of 1 added at dim.\n",
    "`torch.permute(input, dims)`\t|Returns a view of the original input with its dimensions permuted (rearranged) to dims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "torch.Size([10])\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "tensor([[0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(0., 10.)\n",
    "print(x)\n",
    "print(x.shape)\n",
    "\n",
    "x_reshaped = x.reshape(10)\n",
    "print(x_reshaped)\n",
    "x_reshaped = x.reshape(1, 10)\n",
    "print(x_reshaped)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view\n",
    "A tensor view in PyTorch is a way to create a new tensor that shares the same data as the original tensor but has a different shape or strides.\n",
    "\n",
    "Views are used to reshape, transpose, or otherwise change the view of the data without copying the underlying data.\n",
    "This makes operations more memory-efficient and faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 1., 2., 3., 4.],\n",
       "         [5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 1., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(x)\n",
    "z = x.view(2, 5)\n",
    "print(z)\n",
    "\n",
    "# Changing view (z) changes x\n",
    "z[:, 0] = 5\n",
    "z, x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [5., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "tensor([[5., 5., 5., 5.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [4., 4., 4., 4.],\n",
      "        [5., 5., 5., 5.],\n",
      "        [6., 6., 6., 6.],\n",
      "        [7., 7., 7., 7.],\n",
      "        [8., 8., 8., 8.],\n",
      "        [9., 9., 9., 9.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Stack tensors on top of each other\n",
    "x_stacked = torch.stack([x, x, x, x], dim=0) # try changing dim to dim=1 and see what happens\n",
    "print(x_stacked)\n",
    "\n",
    "x_stacked = torch.stack([x, x, x, x], dim=1)\n",
    "\n",
    "print(x_stacked)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Squeeze---\n",
      "Previous tensor: tensor([[5., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous shape: torch.Size([1, 10])\n",
      "\n",
      "New tensor: tensor([5., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New shape: torch.Size([10])\n",
      "---Unsqueeze---\n",
      "Previous tensor: tensor([5., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "Previous shape: torch.Size([10])\n",
      "\n",
      "New tensor: tensor([[5., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "New shape: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Stack tensors on top of each other\n",
    "print(\"---Squeeze---\")\n",
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New shape: {x_squeezed.shape}\")\n",
    "\n",
    "print(\"---Unsqueeze---\")\n",
    "print(f\"Previous tensor: {x_squeezed}\")\n",
    "print(f\"Previous shape: {x_squeezed.shape}\")\n",
    "\n",
    "# And to do the reverse of torch.squeeze() you can use torch.unsqueeze() to add a dimension value of 1 at a specific index.\n",
    "## Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Permute-----\n",
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"-----Permute-----\")\n",
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224, 224, 3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensors)\n",
    "\n",
    "Sometimes you'll want to select specific data from tensors (for example, only the first column or second row)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x =  tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "x.shape =  torch.Size([1, 3, 3])\n",
      "--------\n",
      "x[0] = First square bracket = tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "x[0][0] = Second square bracket = tensor([1, 2, 3])\n",
      "x[0][0][0] = Third square bracket = 1\n",
      "tensor([[1, 4, 7]])\n",
      "tensor([[1, 2, 3]])\n",
      "tensor([[2, 5, 8]])\n",
      "tensor([5])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor \n",
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "print(\"x = \", x)\n",
    "print(\"x.shape = \", x.shape)\n",
    "print(\"--------\")\n",
    "\n",
    "# Let's index bracket by bracket\n",
    "print(f\"x[0] = First square bracket = {x[0]}\") \n",
    "print(f\"x[0][0] = Second square bracket = {x[0][0]}\") \n",
    "print(f\"x[0][0][0] = Third square bracket = {x[0][0][0]}\")\n",
    "\n",
    "print(x[:, :, 0])\n",
    "\n",
    "# You can also use : to specify \"all values in this dimension\" and then use a comma (,) to add another dimension.\n",
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "print(x[:, 0])\n",
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "print(x[:, :, 1])\n",
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "print(x[:, 1, 1])\n",
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension \n",
    "print(x[0, 0, :]) # same as x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch tensors & NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
